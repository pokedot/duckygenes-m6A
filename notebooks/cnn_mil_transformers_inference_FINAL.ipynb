{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b271f24",
   "metadata": {},
   "source": [
    "# Transformer-MIL Inference\n",
    "\n",
    "This notebook reproduces the preprocessing and model architecture used for training, loads a saved checkpoint, and runs inference on unlabeled data to produce per-site probabilities.\n",
    "\n",
    "Usage notes:\n",
    "- Edit the parameters in the next code cell before running.\n",
    "- The notebook will try to reuse a saved scaler if provided; otherwise it will fit a StandardScaler on the inference data (not ideal but a fallback).\n",
    "- The model architecture is identical to training so that state dicts load cleanly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "615d3e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import gzip\n",
    "import joblib\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pprint\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "from torch.cuda.amp import GradScaler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35868c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters (edit before running)\n",
    "DATA = 'dataset2' # dataset name\n",
    "DATA_FILE = f'../data/{DATA}.json.gz'\n",
    "MODEL_PATH = '../models/final_model_state_dict.pt'\n",
    "SCALER_PATH = '../models/' \n",
    "OUTPUT_CSV = f'../predictions/{DATA}_predictions_transformers.csv'\n",
    "BATCH_SIZE = 64\n",
    "BAG_SIZE = 40\n",
    "VERBOSE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a03c6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading raw data: 100%|██████████| 121838/121838 [00:32<00:00, 3747.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 11027106 reads from 121838 sites\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>transcript_position</th>\n",
       "      <th>sequence</th>\n",
       "      <th>dwell_-1</th>\n",
       "      <th>std_-1</th>\n",
       "      <th>mean_-1</th>\n",
       "      <th>dwell_0</th>\n",
       "      <th>std_0</th>\n",
       "      <th>mean_0</th>\n",
       "      <th>dwell_+1</th>\n",
       "      <th>std_+1</th>\n",
       "      <th>mean_+1</th>\n",
       "      <th>mean_0_minus_mean_-1</th>\n",
       "      <th>mean_0_minus_mean_+1</th>\n",
       "      <th>dwell_0_minus_dwell_-1</th>\n",
       "      <th>dwell_0_minus_dwell_+1</th>\n",
       "      <th>std_0_minus_avg_neighbor_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.00299</td>\n",
       "      <td>2.06</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.01770</td>\n",
       "      <td>10.40</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.00930</td>\n",
       "      <td>10.90</td>\n",
       "      <td>84.1</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>37.9</td>\n",
       "      <td>0.01471</td>\n",
       "      <td>0.00840</td>\n",
       "      <td>3.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.00631</td>\n",
       "      <td>2.53</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.00844</td>\n",
       "      <td>4.67</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.01030</td>\n",
       "      <td>6.30</td>\n",
       "      <td>80.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.1</td>\n",
       "      <td>0.00213</td>\n",
       "      <td>-0.00186</td>\n",
       "      <td>0.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>3.92</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.01360</td>\n",
       "      <td>12.00</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.00498</td>\n",
       "      <td>2.13</td>\n",
       "      <td>79.6</td>\n",
       "      <td>15.0</td>\n",
       "      <td>44.4</td>\n",
       "      <td>0.00895</td>\n",
       "      <td>0.00862</td>\n",
       "      <td>8.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.00398</td>\n",
       "      <td>2.06</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.00830</td>\n",
       "      <td>5.01</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.00498</td>\n",
       "      <td>3.78</td>\n",
       "      <td>80.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.6</td>\n",
       "      <td>0.00432</td>\n",
       "      <td>0.00332</td>\n",
       "      <td>2.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.00664</td>\n",
       "      <td>2.92</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.00266</td>\n",
       "      <td>3.94</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.01300</td>\n",
       "      <td>7.15</td>\n",
       "      <td>82.2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>46.8</td>\n",
       "      <td>-0.00398</td>\n",
       "      <td>-0.01034</td>\n",
       "      <td>-1.095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     transcript_id  transcript_position sequence  dwell_-1  std_-1  mean_-1  \\\n",
       "0  ENST00000000233                  244  AAGACCA   0.00299    2.06    125.0   \n",
       "1  ENST00000000233                  244  AAGACCA   0.00631    2.53    125.0   \n",
       "2  ENST00000000233                  244  AAGACCA   0.00465    3.92    109.0   \n",
       "3  ENST00000000233                  244  AAGACCA   0.00398    2.06    125.0   \n",
       "4  ENST00000000233                  244  AAGACCA   0.00664    2.92    120.0   \n",
       "\n",
       "   dwell_0  std_0  mean_0  dwell_+1  std_+1  mean_+1  mean_0_minus_mean_-1  \\\n",
       "0  0.01770  10.40   122.0   0.00930   10.90     84.1                  -3.0   \n",
       "1  0.00844   4.67   126.0   0.01030    6.30     80.9                   1.0   \n",
       "2  0.01360  12.00   124.0   0.00498    2.13     79.6                  15.0   \n",
       "3  0.00830   5.01   130.0   0.00498    3.78     80.4                   5.0   \n",
       "4  0.00266   3.94   129.0   0.01300    7.15     82.2                   9.0   \n",
       "\n",
       "   mean_0_minus_mean_+1  dwell_0_minus_dwell_-1  dwell_0_minus_dwell_+1  \\\n",
       "0                  37.9                 0.01471                 0.00840   \n",
       "1                  45.1                 0.00213                -0.00186   \n",
       "2                  44.4                 0.00895                 0.00862   \n",
       "3                  49.6                 0.00432                 0.00332   \n",
       "4                  46.8                -0.00398                -0.01034   \n",
       "\n",
       "   std_0_minus_avg_neighbor_std  \n",
       "0                         3.920  \n",
       "1                         0.255  \n",
       "2                         8.975  \n",
       "3                         2.090  \n",
       "4                        -1.095  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load raw JSON.gz and build DataFrame of reads (no labels expected)\n",
    "def load_unlabeled_data(data_file):\n",
    "    rows = []\n",
    "    with gzip.open(data_file, 'rt', encoding='utf-8') as f:\n",
    "        total = sum(1 for _ in f)\n",
    "    with gzip.open(data_file, 'rt', encoding='utf-8') as f:\n",
    "        for line in tqdm(f, total=total, desc='Loading raw data'):\n",
    "            data = json.loads(line)\n",
    "            for transcript_id, positions in data.items():\n",
    "                for transcript_position, sequences in positions.items():\n",
    "                    for sequence, feature_list in sequences.items():\n",
    "                        for features in feature_list:\n",
    "                            rows.append({\n",
    "                                'transcript_id': transcript_id,\n",
    "                                'transcript_position': int(transcript_position),\n",
    "                                'sequence': sequence,\n",
    "                                'dwell_-1': features[0],\n",
    "                                'std_-1': features[1],\n",
    "                                'mean_-1': features[2],\n",
    "                                'dwell_0': features[3],\n",
    "                                'std_0': features[4],\n",
    "                                'mean_0': features[5],\n",
    "                                'dwell_+1': features[6],\n",
    "                                'std_+1': features[7],\n",
    "                                'mean_+1': features[8],\n",
    "                            })\n",
    "    df = pd.DataFrame(rows)\n",
    "    # Add derived features same as training\n",
    "    df['mean_0_minus_mean_-1'] = df['mean_0'] - df['mean_-1']\n",
    "    df['mean_0_minus_mean_+1'] = df['mean_0'] - df['mean_+1']\n",
    "    df['dwell_0_minus_dwell_-1'] = df['dwell_0'] - df['dwell_-1']\n",
    "    df['dwell_0_minus_dwell_+1'] = df['dwell_0'] - df['dwell_+1']\n",
    "    df['std_0_minus_avg_neighbor_std'] = df['std_0'] - ((df['std_-1'] + df['std_+1']) / 2.0)\n",
    "    if VERBOSE:\n",
    "        # Use string column names for grouping to avoid KeyError when variables of same names exist\n",
    "        n_sites = df.groupby(['transcript_id', 'transcript_position']).ngroups if not df.empty else 0\n",
    "        print(f'Loaded {len(df)} reads from {n_sites} sites')\n",
    "    return df\n",
    "\n",
    "# Run load\n",
    "df_raw = load_unlabeled_data(DATA_FILE)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6484ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding helpers and numeric feature list\n",
    "BASE2IDX = {'A':0, 'C':1, 'G':2, 'T':3, 'U':3}\n",
    "PAD_IDX = 4\n",
    "\n",
    "def seq_to_idx7(s: str):\n",
    "    s = str(s).upper().replace('U', 'T')\n",
    "    return np.array([BASE2IDX.get(ch, 0) for ch in s], dtype=np.int64)\n",
    "\n",
    "# numeric columns used by model (must match training)\n",
    "num_cols = [\n",
    "    'dwell_-1','std_-1','mean_-1',\n",
    "    'dwell_0','std_0','mean_0',\n",
    "    'dwell_+1','std_+1','mean_+1',\n",
    "    'mean_0_minus_mean_-1',\n",
    "    'mean_0_minus_mean_+1',\n",
    "    'dwell_0_minus_dwell_-1',\n",
    "    'dwell_0_minus_dwell_+1',\n",
    "    'std_0_minus_avg_neighbor_std'\n",
    "]\n",
    "seq_col = 'sequence'\n",
    "site_key = ['transcript_id', 'transcript_position']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de418285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 121838 bags from 121838 sites\n"
     ]
    }
   ],
   "source": [
    "# Create bags for unlabeled data (labels set to 0 as placeholder)\n",
    "def create_bags_unlabeled(df, site_key, num_cols, seq_col, min_reads=1, max_reads=50):\n",
    "    bags = []\n",
    "    grouped = df.groupby(site_key)\n",
    "    for site, group in grouped:\n",
    "        if len(group) < min_reads:\n",
    "            continue\n",
    "        features = group[num_cols].to_numpy(dtype=np.float32)\n",
    "        sequences = group[seq_col].astype(str).tolist()\n",
    "        seq_idx = np.vstack([seq_to_idx7(s) for s in sequences])\n",
    "        n = len(features)\n",
    "        if n > max_reads:\n",
    "            idx = np.random.choice(n, max_reads, replace=False)\n",
    "            features = features[idx]\n",
    "            seq_idx = seq_idx[idx]\n",
    "        bags.append({\n",
    "            'site': site,\n",
    "            'transcript_id': site[0],\n",
    "            'transcript_position': int(site[1]),\n",
    "            'features': features,\n",
    "            'seq_idx': seq_idx,\n",
    "            'n_reads': len(features),\n",
    "            'label': 0,  # placeholder\n",
    "            'gene_id': ''\n",
    "        })\n",
    "    print(f'Created {len(bags)} bags from {len(grouped)} sites')\n",
    "    return bags\n",
    "\n",
    "# Build bags from raw dataframe\n",
    "bags = create_bags_unlabeled(df_raw, site_key, num_cols, seq_col, min_reads=1, max_reads=BAG_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47183f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 121838 bags, DataLoader batches: 1904\n"
     ]
    }
   ],
   "source": [
    "# Reuse RNA_MIL_Dataset but without oversampling (labels are placeholders)\n",
    "class RNA_MIL_Dataset_Unlabeled(Dataset):\n",
    "    def __init__(self, bags, bag_size=40, pad_idx=PAD_IDX):\n",
    "        self.proc = []\n",
    "        self.meta = []\n",
    "        for bag in bags:\n",
    "            num = bag['features']\n",
    "            seq = bag['seq_idx']\n",
    "            n = bag['n_reads']\n",
    "            if n == 0:\n",
    "                continue\n",
    "            if n < bag_size:\n",
    "                pad_num = np.zeros((bag_size - n, num.shape[1]), dtype=np.float32)\n",
    "                pad_seq = np.full((bag_size - n, seq.shape[1]), pad_idx, dtype=np.int64)\n",
    "                num_fixed = np.vstack([num, pad_num])\n",
    "                seq_fixed = np.vstack([seq, pad_seq])\n",
    "                mask = np.zeros(bag_size, dtype=np.float32)\n",
    "                mask[:n] = 1.0\n",
    "            else:\n",
    "                if n > bag_size:\n",
    "                    idx = np.arange(n)[:bag_size]\n",
    "                    num_fixed = num[idx].astype(np.float32)\n",
    "                    seq_fixed = seq[idx].astype(np.int64)\n",
    "                    mask = np.ones(bag_size, dtype=np.float32)\n",
    "                else:\n",
    "                    num_fixed = num.astype(np.float32)\n",
    "                    seq_fixed = seq.astype(np.int64)\n",
    "                    mask = np.ones(bag_size, dtype=np.float32)\n",
    "            self.proc.append({'num': num_fixed, 'seq': seq_fixed, 'mask': mask})\n",
    "            self.meta.append({'transcript_id': bag['transcript_id'], 'transcript_position': bag['transcript_position'], 'n_reads': bag['n_reads']})\n",
    "    def __len__(self):\n",
    "        return len(self.proc)\n",
    "    def __getitem__(self, idx):\n",
    "        b = self.proc[idx]\n",
    "        x_num = torch.from_numpy(b['num'])\n",
    "        x_seq = torch.from_numpy(b['seq'])\n",
    "        mask  = torch.from_numpy(b['mask'])\n",
    "        return x_num, x_seq, mask\n",
    "    def get_metadata(self, idx):\n",
    "        return self.meta[idx]\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = RNA_MIL_Dataset_Unlabeled(bags, bag_size=BAG_SIZE, pad_idx=PAD_IDX)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "print(f'Dataset size: {len(dataset)} bags, DataLoader batches: {len(dataloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca828a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model classes (copied from training notebook, unchanged)\n",
    "class SeqEmbCNN(nn.Module):\n",
    "    def __init__(self, vocab=5, d_emb=8, kernel_sizes=(2,3,4,5), n_filters=32, d_out=64):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab, d_emb, padding_idx=PAD_IDX)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(d_emb, n_filters, ks, padding=0) for ks in kernel_sizes\n",
    "        ])\n",
    "        self.attentions = nn.ModuleList([\n",
    "            nn.Linear(n_filters, 1) for _ in kernel_sizes\n",
    "        ])\n",
    "        self.proj = nn.Linear(n_filters * len(kernel_sizes), d_out)\n",
    "        self.norm = nn.LayerNorm(d_out)\n",
    "    def forward(self, x_idx):\n",
    "        X = self.emb(x_idx).transpose(1,2)\n",
    "        feats = []\n",
    "        for conv, att in zip(self.convs, self.attentions):\n",
    "            h = torch.nn.functional.gelu(conv(X))\n",
    "            h_t = h.permute(0,2,1)\n",
    "            scores = att(h_t).squeeze(-1)\n",
    "            weights = torch.nn.functional.softmax(scores, dim=1).unsqueeze(-1)\n",
    "            pooled = (h_t * weights).sum(dim=1)\n",
    "            feats.append(pooled)\n",
    "        z = torch.cat(feats, dim=1)\n",
    "        z = self.proj(z)\n",
    "        return self.norm(torch.nn.functional.gelu(z))\n",
    "\n",
    "class GatedAttentionPooling(nn.Module):\n",
    "    def __init__(self, d_model, n_heads=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.attention_heads = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(d_model, d_model), nn.Tanh(), nn.Dropout(dropout), nn.Linear(d_model,1)) for _ in range(n_heads)\n",
    "        ])\n",
    "        self.gate = nn.Sequential(nn.Linear(d_model, d_model//2), nn.ReLU(), nn.Dropout(dropout), nn.Linear(d_model//2,1), nn.Sigmoid())\n",
    "        self.fusion = nn.Sequential(nn.Linear(d_model * n_heads, d_model), nn.LayerNorm(d_model), nn.GELU())\n",
    "    def forward(self, h, mask):\n",
    "        gates = self.gate(h).squeeze(-1) * mask\n",
    "        pooled = []\n",
    "        all_weights = []\n",
    "        for attn in self.attention_heads:\n",
    "            scores = attn(h).squeeze(-1)\n",
    "            gated_scores = scores * gates\n",
    "            gated_scores = gated_scores.masked_fill(mask == 0, float('-inf'))\n",
    "            weights = torch.nn.functional.softmax(gated_scores, dim=1).unsqueeze(-1)\n",
    "            pooled.append((h * weights).sum(dim=1))\n",
    "            all_weights.append(weights.squeeze(-1))\n",
    "        bag_repr = self.fusion(torch.cat(pooled, dim=-1))\n",
    "        avg_weights = torch.stack(all_weights, dim=0).mean(dim=0)\n",
    "        return bag_repr, avg_weights, gates\n",
    "\n",
    "class TransformerMIL(nn.Module):\n",
    "    def __init__(self, num_features=9, d_model=128, n_heads=4, n_layers=4, d_ff=1024, dropout=0.1, attn_pool_heads=4, instance_dropout=0.15):\n",
    "        super().__init__()\n",
    "        self.instance_dropout = instance_dropout\n",
    "        self.seq_encoder = SeqEmbCNN(vocab=5, d_emb=8, kernel_sizes=(2,3,4,5), n_filters=32, d_out=64)\n",
    "        self.num_proj = nn.Sequential(nn.Linear(num_features, 64), nn.LayerNorm(64), nn.GELU(), nn.Dropout(dropout))\n",
    "        self.feature_fusion = nn.Sequential(nn.Linear(128, d_model), nn.LayerNorm(d_model), nn.GELU(), nn.Dropout(dropout), nn.Linear(d_model, d_model), nn.LayerNorm(d_model))\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=n_heads, dim_feedforward=d_ff, dropout=dropout, activation='gelu', batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        self.attention_pool = GatedAttentionPooling(d_model, n_heads=attn_pool_heads, dropout=dropout)\n",
    "        self.classifier = nn.Sequential(nn.Linear(d_model, d_model//2), nn.LayerNorm(d_model//2), nn.GELU(), nn.Dropout(dropout), nn.Linear(d_model//2, d_model//4), nn.LayerNorm(d_model//4), nn.GELU(), nn.Dropout(dropout), nn.Linear(d_model//4, 1))\n",
    "        self.instance_classifier = nn.Sequential(nn.Linear(d_model, d_model//2), nn.LayerNorm(d_model//2), nn.GELU(), nn.Dropout(dropout), nn.Linear(d_model//2, d_model//4), nn.GELU(), nn.Dropout(dropout), nn.Linear(d_model//4, 1))\n",
    "    def encode_sequences(self, x_seq):\n",
    "        B, K, L = x_seq.shape\n",
    "        seq_flat = x_seq.reshape(B * K, L)\n",
    "        z_seq = self.seq_encoder(seq_flat)\n",
    "        return z_seq.view(B, K, -1)\n",
    "    def apply_instance_dropout(self, mask):\n",
    "        if not self.training or self.instance_dropout == 0:\n",
    "            return mask\n",
    "        B, K = mask.shape\n",
    "        dropout_mask = torch.rand(B, K, device=mask.device) > self.instance_dropout\n",
    "        n_keep = (dropout_mask * mask).sum(dim=1, keepdim=True)\n",
    "        too_few = n_keep < 5\n",
    "        dropout_mask = torch.where(too_few, torch.ones_like(dropout_mask), dropout_mask)\n",
    "        return mask * dropout_mask.float()\n",
    "    def forward(self, x_num, mask, x_seq=None):\n",
    "        B, K, _ = x_num.shape\n",
    "        effective_mask = self.apply_instance_dropout(mask)\n",
    "        num_features = self.num_proj(x_num)\n",
    "        if x_seq is not None:\n",
    "            seq_features = self.encode_sequences(x_seq)\n",
    "            combined = torch.cat([num_features, seq_features], dim=-1)\n",
    "        else:\n",
    "            combined = num_features\n",
    "        h = self.feature_fusion(combined)\n",
    "        src_key_padding_mask = (effective_mask == 0)\n",
    "        h = self.transformer(h, src_key_padding_mask=src_key_padding_mask)\n",
    "        instance_logits = self.instance_classifier(h).squeeze(-1)\n",
    "        instance_logits = instance_logits.masked_fill(effective_mask == 0, float('-inf'))\n",
    "        bag_repr, attention_weights, gates = self.attention_pool(h, effective_mask)\n",
    "        bag_logits = self.classifier(bag_repr).squeeze(-1)\n",
    "        return bag_logits, attention_weights, instance_logits, gates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4632f4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model weights from ../models/final_model_state_dict.pt\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model and load weights\n",
    "model = TransformerMIL(num_features=len(num_cols))\n",
    "device = torch.device(DEVICE)\n",
    "model = model.to(device)\n",
    "\n",
    "# Try loading different checkpoint formats\n",
    "if MODEL_PATH is not None and Path(MODEL_PATH).exists():\n",
    "    ckpt = torch.load(MODEL_PATH, map_location=device)\n",
    "    # If it's a plain state_dict (mapping of tensors), load directly\n",
    "    if isinstance(ckpt, dict) and any(k.startswith('model') or k.endswith('state_dict') for k in ckpt.keys()):\n",
    "        # support different key names\n",
    "        if 'model_state' in ckpt:\n",
    "            state = ckpt['model_state']\n",
    "        elif 'model_state_dict' in ckpt:\n",
    "            state = ckpt['model_state_dict']\n",
    "        elif 'model' in ckpt and isinstance(ckpt['model'], dict):\n",
    "            state = ckpt['model']\n",
    "        else:\n",
    "            # assume ckpt itself is state_dict-like\n",
    "            state = ckpt\n",
    "    else:\n",
    "        state = ckpt\n",
    "    model.load_state_dict(state)\n",
    "    print(f'Loaded model weights from {MODEL_PATH}')\n",
    "else:\n",
    "    print(f'MODEL_PATH does not exist: {MODEL_PATH}. Please set MODEL_PATH to a valid checkpoint.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d6a072e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded feature scaler from ..\\models\\scaler.joblib\n",
      "Loaded AMP GradScaler from ..\\models\\amp_grad_scaler.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\inbam\\AppData\\Local\\Temp\\ipykernel_32540\\261539347.py:35: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  amp_scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied feature scaler to df_raw\n",
      "Created 121838 bags from 121838 sites\n",
      "Dataset size: 121838 bags, DataLoader batches: 1904\n"
     ]
    }
   ],
   "source": [
    "# Scaler loading (explicit scaler_path and amp_path; minimal/no error-handling)\n",
    "# Define explicit paths (prefer SCALER_PATH if provided, else candidate next to MODEL_PATH)\n",
    "scaler_path = 'scaler.joblib'\n",
    "if SCALER_PATH:\n",
    "    p = Path(SCALER_PATH)\n",
    "    scaler_path = p if p.is_file() else (p / 'scaler.joblib')\n",
    "elif MODEL_PATH:\n",
    "    scaler_path = Path(MODEL_PATH).parent / 'scaler.joblib'\n",
    "\n",
    "amp_path = 'amp_grad_scaler.pt'\n",
    "if SCALER_PATH:\n",
    "    p = Path(SCALER_PATH)\n",
    "    amp_path = (p / 'amp_grad_scaler.pt') if p.is_dir() else (p if p.name == 'amp_grad_scaler.pt' else None)\n",
    "elif MODEL_PATH:\n",
    "    amp_path = Path(MODEL_PATH).parent / 'amp_grad_scaler.pt'\n",
    "\n",
    "# Load feature scaler if scaler_path exists\n",
    "feature_scaler = None\n",
    "saved_num_cols = None\n",
    "if scaler_path is not None and Path(scaler_path).exists():\n",
    "    payload = joblib.load(scaler_path)\n",
    "    if isinstance(payload, dict) and 'scaler' in payload:\n",
    "        feature_scaler = payload['scaler']\n",
    "        saved_num_cols = payload.get('num_cols', None)\n",
    "    else:\n",
    "        feature_scaler = payload\n",
    "    print(f'Loaded feature scaler from {scaler_path}')\n",
    "else:\n",
    "    print('No scaler_path found; feature_scaler remains None')\n",
    "\n",
    "# Load AMP GradScaler directly if amp_path exists (minimal loading)\n",
    "amp_scaler = None\n",
    "if amp_path is not None and Path(amp_path).exists():\n",
    "    amp_state = torch.load(amp_path, map_location='cpu')\n",
    "    amp_scaler = GradScaler()\n",
    "    amp_scaler.load_state_dict(amp_state)\n",
    "    print(f'Loaded AMP GradScaler from {amp_path}')\n",
    "else:\n",
    "    print('No amp_path found; amp_scaler remains None')\n",
    "\n",
    "# Verify column consistency when possible\n",
    "if feature_scaler is not None and saved_num_cols is not None:\n",
    "    if list(saved_num_cols) != list(num_cols):\n",
    "        print('WARNING: numeric column list in saved scaler differs from current num_cols.')\n",
    "        print(f'Saved: {saved_num_cols}')\n",
    "        print(f'Current: {num_cols}')\n",
    "    else:\n",
    "        print('Saved scaler column order matches current num_cols')\n",
    "\n",
    "# Apply scaling if we have a feature scaler\n",
    "if feature_scaler is not None:\n",
    "    df_raw[num_cols] = feature_scaler.transform(df_raw[num_cols])\n",
    "    print('Applied feature scaler to df_raw')\n",
    "\n",
    "# Rebuild bags and dataset now that df_raw is scaled\n",
    "bags = create_bags_unlabeled(df_raw, site_key, num_cols, seq_col, min_reads=1, max_reads=BAG_SIZE)\n",
    "dataset = RNA_MIL_Dataset_Unlabeled(bags, bag_size=BAG_SIZE, pad_idx=PAD_IDX)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "print(f'Dataset size: {len(dataset)} bags, DataLoader batches: {len(dataloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a009bed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference:   0%|          | 0/1904 [00:00<?, ?it/s]C:\\Users\\inbam\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\transformer.py:515: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\NestedTensorImpl.cpp:182.)\n",
      "  output = torch._nested_tensor_from_mask(\n",
      "Running inference: 100%|██████████| 1904/1904 [00:28<00:00, 66.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to ..\\predictions\\dataset0_predictions_transformers.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>transcript_position</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>0.033128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>261</td>\n",
       "      <td>0.145133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>316</td>\n",
       "      <td>0.065267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>332</td>\n",
       "      <td>0.650352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>368</td>\n",
       "      <td>0.091795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     transcript_id  transcript_position     score\n",
       "0  ENST00000000233                  244  0.033128\n",
       "1  ENST00000000233                  261  0.145133\n",
       "2  ENST00000000233                  316  0.065267\n",
       "3  ENST00000000233                  332  0.650352\n",
       "4  ENST00000000233                  368  0.091795"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run inference and save per-site probabilities\n",
    "model.eval()\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(tqdm(dataloader, desc='Running inference')):\n",
    "        x_num, x_seq, mask = batch\n",
    "        x_num = x_num.to(device)\n",
    "        x_seq = x_seq.to(device)\n",
    "        mask  = mask.to(device)\n",
    "        bag_logits, attn, inst_logits, gates = model(x_num=x_num, x_seq=x_seq, mask=mask)\n",
    "        probs = torch.sigmoid(bag_logits).cpu().numpy()\n",
    "        batch_start = batch_idx * BATCH_SIZE\n",
    "        for i in range(len(probs)):\n",
    "            meta = dataset.get_metadata(batch_start + i)\n",
    "            results.append({\n",
    "                'transcript_id': meta['transcript_id'],\n",
    "                'transcript_position': meta['transcript_position'],\n",
    "                'score': float(probs[i])\n",
    "            })\n",
    "\n",
    "# Build DataFrame and save\n",
    "pred_df = pd.DataFrame(results)\n",
    "out_path = Path(OUTPUT_CSV)\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "pred_df.to_csv(out_path, index=False)\n",
    "print(f'Saved predictions to {out_path}')\n",
    "pred_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
