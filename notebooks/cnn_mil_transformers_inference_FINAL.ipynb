{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b271f24",
   "metadata": {},
   "source": [
    "# Transformer-MIL Inference\n",
    "\n",
    "This notebook reproduces the preprocessing and model architecture used for training, loads a saved checkpoint, and runs inference on unlabeled data to produce per-site probabilities.\n",
    "\n",
    "Usage notes:\n",
    "- Edit the parameters in the next code cell before running.\n",
    "- The notebook will try to reuse a saved scaler if provided; otherwise it will fit a StandardScaler on the inference data (not ideal but a fallback).\n",
    "- The model architecture is identical to training so that state dicts load cleanly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "615d3e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import gzip, json, os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {DEVICE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c35868c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters (edit before running)\n",
    "DATA_FILE = '../data/dataset0.json.gz'  # raw JSON.gz used at training time\n",
    "MODEL_PATH = '../runs/run_20251029_105547/checkpoints/final_model_state_dict.pt'\n",
    "SCALER_PATH = '../runs/run_20251029_105547/checkpoints/' \n",
    "OUTPUT_CSV = '../predictions/dataset0_predictions_transformers.csv'\n",
    "BATCH_SIZE = 64\n",
    "BAG_SIZE = 40\n",
    "VERBOSE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a03c6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading raw data: 100%|██████████| 121838/121838 [01:00<00:00, 2007.41it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 11027106 reads from 121838 sites\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>transcript_position</th>\n",
       "      <th>sequence</th>\n",
       "      <th>dwell_-1</th>\n",
       "      <th>std_-1</th>\n",
       "      <th>mean_-1</th>\n",
       "      <th>dwell_0</th>\n",
       "      <th>std_0</th>\n",
       "      <th>mean_0</th>\n",
       "      <th>dwell_+1</th>\n",
       "      <th>std_+1</th>\n",
       "      <th>mean_+1</th>\n",
       "      <th>mean_0_minus_mean_-1</th>\n",
       "      <th>mean_0_minus_mean_+1</th>\n",
       "      <th>dwell_0_minus_dwell_-1</th>\n",
       "      <th>dwell_0_minus_dwell_+1</th>\n",
       "      <th>std_0_minus_avg_neighbor_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.00299</td>\n",
       "      <td>2.06</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.01770</td>\n",
       "      <td>10.40</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.00930</td>\n",
       "      <td>10.90</td>\n",
       "      <td>84.1</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>37.9</td>\n",
       "      <td>0.01471</td>\n",
       "      <td>0.00840</td>\n",
       "      <td>3.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.00631</td>\n",
       "      <td>2.53</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.00844</td>\n",
       "      <td>4.67</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.01030</td>\n",
       "      <td>6.30</td>\n",
       "      <td>80.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.1</td>\n",
       "      <td>0.00213</td>\n",
       "      <td>-0.00186</td>\n",
       "      <td>0.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>3.92</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.01360</td>\n",
       "      <td>12.00</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.00498</td>\n",
       "      <td>2.13</td>\n",
       "      <td>79.6</td>\n",
       "      <td>15.0</td>\n",
       "      <td>44.4</td>\n",
       "      <td>0.00895</td>\n",
       "      <td>0.00862</td>\n",
       "      <td>8.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.00398</td>\n",
       "      <td>2.06</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.00830</td>\n",
       "      <td>5.01</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.00498</td>\n",
       "      <td>3.78</td>\n",
       "      <td>80.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.6</td>\n",
       "      <td>0.00432</td>\n",
       "      <td>0.00332</td>\n",
       "      <td>2.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.00664</td>\n",
       "      <td>2.92</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.00266</td>\n",
       "      <td>3.94</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.01300</td>\n",
       "      <td>7.15</td>\n",
       "      <td>82.2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>46.8</td>\n",
       "      <td>-0.00398</td>\n",
       "      <td>-0.01034</td>\n",
       "      <td>-1.095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     transcript_id  transcript_position sequence  dwell_-1  std_-1  mean_-1  \\\n",
       "0  ENST00000000233                  244  AAGACCA   0.00299    2.06    125.0   \n",
       "1  ENST00000000233                  244  AAGACCA   0.00631    2.53    125.0   \n",
       "2  ENST00000000233                  244  AAGACCA   0.00465    3.92    109.0   \n",
       "3  ENST00000000233                  244  AAGACCA   0.00398    2.06    125.0   \n",
       "4  ENST00000000233                  244  AAGACCA   0.00664    2.92    120.0   \n",
       "\n",
       "   dwell_0  std_0  mean_0  dwell_+1  std_+1  mean_+1  mean_0_minus_mean_-1  \\\n",
       "0  0.01770  10.40   122.0   0.00930   10.90     84.1                  -3.0   \n",
       "1  0.00844   4.67   126.0   0.01030    6.30     80.9                   1.0   \n",
       "2  0.01360  12.00   124.0   0.00498    2.13     79.6                  15.0   \n",
       "3  0.00830   5.01   130.0   0.00498    3.78     80.4                   5.0   \n",
       "4  0.00266   3.94   129.0   0.01300    7.15     82.2                   9.0   \n",
       "\n",
       "   mean_0_minus_mean_+1  dwell_0_minus_dwell_-1  dwell_0_minus_dwell_+1  \\\n",
       "0                  37.9                 0.01471                 0.00840   \n",
       "1                  45.1                 0.00213                -0.00186   \n",
       "2                  44.4                 0.00895                 0.00862   \n",
       "3                  49.6                 0.00432                 0.00332   \n",
       "4                  46.8                -0.00398                -0.01034   \n",
       "\n",
       "   std_0_minus_avg_neighbor_std  \n",
       "0                         3.920  \n",
       "1                         0.255  \n",
       "2                         8.975  \n",
       "3                         2.090  \n",
       "4                        -1.095  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load raw JSON.gz and build DataFrame of reads (no labels expected)\n",
    "def load_unlabeled_data(data_file):\n",
    "    rows = []\n",
    "    with gzip.open(data_file, 'rt', encoding='utf-8') as f:\n",
    "        total = sum(1 for _ in f)\n",
    "    with gzip.open(data_file, 'rt', encoding='utf-8') as f:\n",
    "        for line in tqdm(f, total=total, desc='Loading raw data'):\n",
    "            data = json.loads(line)\n",
    "            for transcript_id, positions in data.items():\n",
    "                for transcript_position, sequences in positions.items():\n",
    "                    for sequence, feature_list in sequences.items():\n",
    "                        for features in feature_list:\n",
    "                            rows.append({\n",
    "                                'transcript_id': transcript_id,\n",
    "                                'transcript_position': int(transcript_position),\n",
    "                                'sequence': sequence,\n",
    "                                'dwell_-1': features[0],\n",
    "                                'std_-1': features[1],\n",
    "                                'mean_-1': features[2],\n",
    "                                'dwell_0': features[3],\n",
    "                                'std_0': features[4],\n",
    "                                'mean_0': features[5],\n",
    "                                'dwell_+1': features[6],\n",
    "                                'std_+1': features[7],\n",
    "                                'mean_+1': features[8],\n",
    "                            })\n",
    "    df = pd.DataFrame(rows)\n",
    "    # Add derived features same as training\n",
    "    df['mean_0_minus_mean_-1'] = df['mean_0'] - df['mean_-1']\n",
    "    df['mean_0_minus_mean_+1'] = df['mean_0'] - df['mean_+1']\n",
    "    df['dwell_0_minus_dwell_-1'] = df['dwell_0'] - df['dwell_-1']\n",
    "    df['dwell_0_minus_dwell_+1'] = df['dwell_0'] - df['dwell_+1']\n",
    "    df['std_0_minus_avg_neighbor_std'] = df['std_0'] - ((df['std_-1'] + df['std_+1']) / 2.0)\n",
    "    if VERBOSE:\n",
    "        # Use string column names for grouping to avoid KeyError when variables of same names exist\n",
    "        n_sites = df.groupby(['transcript_id', 'transcript_position']).ngroups if not df.empty else 0\n",
    "        print(f'Loaded {len(df)} reads from {n_sites} sites')\n",
    "    return df\n",
    "\n",
    "# Run load\n",
    "df_raw = load_unlabeled_data(DATA_FILE)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6484ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding helpers and numeric feature list\n",
    "BASE2IDX = {'A':0, 'C':1, 'G':2, 'T':3, 'U':3}\n",
    "PAD_IDX = 4\n",
    "\n",
    "def seq_to_idx7(s: str):\n",
    "    s = str(s).upper().replace('U', 'T')\n",
    "    return np.array([BASE2IDX.get(ch, 0) for ch in s], dtype=np.int64)\n",
    "\n",
    "# numeric columns used by model (must match training)\n",
    "num_cols = [\n",
    "    'dwell_-1','std_-1','mean_-1',\n",
    "    'dwell_0','std_0','mean_0',\n",
    "    'dwell_+1','std_+1','mean_+1',\n",
    "    'mean_0_minus_mean_-1',\n",
    "    'mean_0_minus_mean_+1',\n",
    "    'dwell_0_minus_dwell_-1',\n",
    "    'dwell_0_minus_dwell_+1',\n",
    "    'std_0_minus_avg_neighbor_std'\n",
    "]\n",
    "seq_col = 'sequence'\n",
    "site_key = ['transcript_id', 'transcript_position']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de418285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 121838 bags from 121838 sites\n"
     ]
    }
   ],
   "source": [
    "# Create bags for unlabeled data (labels set to 0 as placeholder)\n",
    "def create_bags_unlabeled(df, site_key, num_cols, seq_col, min_reads=1, max_reads=50):\n",
    "    bags = []\n",
    "    grouped = df.groupby(site_key)\n",
    "    for site, group in grouped:\n",
    "        if len(group) < min_reads:\n",
    "            continue\n",
    "        features = group[num_cols].to_numpy(dtype=np.float32)\n",
    "        sequences = group[seq_col].astype(str).tolist()\n",
    "        seq_idx = np.vstack([seq_to_idx7(s) for s in sequences])\n",
    "        n = len(features)\n",
    "        if n > max_reads:\n",
    "            idx = np.random.choice(n, max_reads, replace=False)\n",
    "            features = features[idx]\n",
    "            seq_idx = seq_idx[idx]\n",
    "        bags.append({\n",
    "            'site': site,\n",
    "            'transcript_id': site[0],\n",
    "            'transcript_position': int(site[1]),\n",
    "            'features': features,\n",
    "            'seq_idx': seq_idx,\n",
    "            'n_reads': len(features),\n",
    "            'label': 0,  # placeholder\n",
    "            'gene_id': ''\n",
    "        })\n",
    "    print(f'Created {len(bags)} bags from {len(grouped)} sites')\n",
    "    return bags\n",
    "\n",
    "# Build bags from raw dataframe\n",
    "bags = create_bags_unlabeled(df_raw, site_key, num_cols, seq_col, min_reads=1, max_reads=BAG_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47183f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 121838 bags, DataLoader batches: 1904\n"
     ]
    }
   ],
   "source": [
    "# Reuse RNA_MIL_Dataset but without oversampling (labels are placeholders)\n",
    "class RNA_MIL_Dataset_Unlabeled(Dataset):\n",
    "    def __init__(self, bags, bag_size=40, pad_idx=PAD_IDX):\n",
    "        self.proc = []\n",
    "        self.meta = []\n",
    "        for bag in bags:\n",
    "            num = bag['features']\n",
    "            seq = bag['seq_idx']\n",
    "            n = bag['n_reads']\n",
    "            if n == 0:\n",
    "                continue\n",
    "            if n < bag_size:\n",
    "                pad_num = np.zeros((bag_size - n, num.shape[1]), dtype=np.float32)\n",
    "                pad_seq = np.full((bag_size - n, seq.shape[1]), pad_idx, dtype=np.int64)\n",
    "                num_fixed = np.vstack([num, pad_num])\n",
    "                seq_fixed = np.vstack([seq, pad_seq])\n",
    "                mask = np.zeros(bag_size, dtype=np.float32)\n",
    "                mask[:n] = 1.0\n",
    "            else:\n",
    "                if n > bag_size:\n",
    "                    idx = np.arange(n)[:bag_size]\n",
    "                    num_fixed = num[idx].astype(np.float32)\n",
    "                    seq_fixed = seq[idx].astype(np.int64)\n",
    "                    mask = np.ones(bag_size, dtype=np.float32)\n",
    "                else:\n",
    "                    num_fixed = num.astype(np.float32)\n",
    "                    seq_fixed = seq.astype(np.int64)\n",
    "                    mask = np.ones(bag_size, dtype=np.float32)\n",
    "            self.proc.append({'num': num_fixed, 'seq': seq_fixed, 'mask': mask})\n",
    "            self.meta.append({'transcript_id': bag['transcript_id'], 'transcript_position': bag['transcript_position'], 'n_reads': bag['n_reads']})\n",
    "    def __len__(self):\n",
    "        return len(self.proc)\n",
    "    def __getitem__(self, idx):\n",
    "        b = self.proc[idx]\n",
    "        x_num = torch.from_numpy(b['num'])\n",
    "        x_seq = torch.from_numpy(b['seq'])\n",
    "        mask  = torch.from_numpy(b['mask'])\n",
    "        return x_num, x_seq, mask\n",
    "    def get_metadata(self, idx):\n",
    "        return self.meta[idx]\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = RNA_MIL_Dataset_Unlabeled(bags, bag_size=BAG_SIZE, pad_idx=PAD_IDX)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "print(f'Dataset size: {len(dataset)} bags, DataLoader batches: {len(dataloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca828a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model classes (copied from training notebook, unchanged)\n",
    "class SeqEmbCNN(nn.Module):\n",
    "    def __init__(self, vocab=5, d_emb=8, kernel_sizes=(2,3,4,5), n_filters=32, d_out=64):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab, d_emb, padding_idx=PAD_IDX)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(d_emb, n_filters, ks, padding=0) for ks in kernel_sizes\n",
    "        ])\n",
    "        self.attentions = nn.ModuleList([\n",
    "            nn.Linear(n_filters, 1) for _ in kernel_sizes\n",
    "        ])\n",
    "        self.proj = nn.Linear(n_filters * len(kernel_sizes), d_out)\n",
    "        self.norm = nn.LayerNorm(d_out)\n",
    "    def forward(self, x_idx):\n",
    "        X = self.emb(x_idx).transpose(1,2)\n",
    "        feats = []\n",
    "        for conv, att in zip(self.convs, self.attentions):\n",
    "            h = torch.nn.functional.gelu(conv(X))\n",
    "            h_t = h.permute(0,2,1)\n",
    "            scores = att(h_t).squeeze(-1)\n",
    "            weights = torch.nn.functional.softmax(scores, dim=1).unsqueeze(-1)\n",
    "            pooled = (h_t * weights).sum(dim=1)\n",
    "            feats.append(pooled)\n",
    "        z = torch.cat(feats, dim=1)\n",
    "        z = self.proj(z)\n",
    "        return self.norm(torch.nn.functional.gelu(z))\n",
    "\n",
    "class GatedAttentionPooling(nn.Module):\n",
    "    def __init__(self, d_model, n_heads=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.attention_heads = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(d_model, d_model), nn.Tanh(), nn.Dropout(dropout), nn.Linear(d_model,1)) for _ in range(n_heads)\n",
    "        ])\n",
    "        self.gate = nn.Sequential(nn.Linear(d_model, d_model//2), nn.ReLU(), nn.Dropout(dropout), nn.Linear(d_model//2,1), nn.Sigmoid())\n",
    "        self.fusion = nn.Sequential(nn.Linear(d_model * n_heads, d_model), nn.LayerNorm(d_model), nn.GELU())\n",
    "    def forward(self, h, mask):\n",
    "        gates = self.gate(h).squeeze(-1) * mask\n",
    "        pooled = []\n",
    "        all_weights = []\n",
    "        for attn in self.attention_heads:\n",
    "            scores = attn(h).squeeze(-1)\n",
    "            gated_scores = scores * gates\n",
    "            gated_scores = gated_scores.masked_fill(mask == 0, float('-inf'))\n",
    "            weights = torch.nn.functional.softmax(gated_scores, dim=1).unsqueeze(-1)\n",
    "            pooled.append((h * weights).sum(dim=1))\n",
    "            all_weights.append(weights.squeeze(-1))\n",
    "        bag_repr = self.fusion(torch.cat(pooled, dim=-1))\n",
    "        avg_weights = torch.stack(all_weights, dim=0).mean(dim=0)\n",
    "        return bag_repr, avg_weights, gates\n",
    "\n",
    "class TransformerMIL(nn.Module):\n",
    "    def __init__(self, num_features=9, d_model=128, n_heads=4, n_layers=4, d_ff=1024, dropout=0.1, attn_pool_heads=4, instance_dropout=0.15):\n",
    "        super().__init__()\n",
    "        self.instance_dropout = instance_dropout\n",
    "        self.seq_encoder = SeqEmbCNN(vocab=5, d_emb=8, kernel_sizes=(2,3,4,5), n_filters=32, d_out=64)\n",
    "        self.num_proj = nn.Sequential(nn.Linear(num_features, 64), nn.LayerNorm(64), nn.GELU(), nn.Dropout(dropout))\n",
    "        self.feature_fusion = nn.Sequential(nn.Linear(128, d_model), nn.LayerNorm(d_model), nn.GELU(), nn.Dropout(dropout), nn.Linear(d_model, d_model), nn.LayerNorm(d_model))\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=n_heads, dim_feedforward=d_ff, dropout=dropout, activation='gelu', batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        self.attention_pool = GatedAttentionPooling(d_model, n_heads=attn_pool_heads, dropout=dropout)\n",
    "        self.classifier = nn.Sequential(nn.Linear(d_model, d_model//2), nn.LayerNorm(d_model//2), nn.GELU(), nn.Dropout(dropout), nn.Linear(d_model//2, d_model//4), nn.LayerNorm(d_model//4), nn.GELU(), nn.Dropout(dropout), nn.Linear(d_model//4, 1))\n",
    "        self.instance_classifier = nn.Sequential(nn.Linear(d_model, d_model//2), nn.LayerNorm(d_model//2), nn.GELU(), nn.Dropout(dropout), nn.Linear(d_model//2, d_model//4), nn.GELU(), nn.Dropout(dropout), nn.Linear(d_model//4, 1))\n",
    "    def encode_sequences(self, x_seq):\n",
    "        B, K, L = x_seq.shape\n",
    "        seq_flat = x_seq.reshape(B * K, L)\n",
    "        z_seq = self.seq_encoder(seq_flat)\n",
    "        return z_seq.view(B, K, -1)\n",
    "    def apply_instance_dropout(self, mask):\n",
    "        if not self.training or self.instance_dropout == 0:\n",
    "            return mask\n",
    "        B, K = mask.shape\n",
    "        dropout_mask = torch.rand(B, K, device=mask.device) > self.instance_dropout\n",
    "        n_keep = (dropout_mask * mask).sum(dim=1, keepdim=True)\n",
    "        too_few = n_keep < 5\n",
    "        dropout_mask = torch.where(too_few, torch.ones_like(dropout_mask), dropout_mask)\n",
    "        return mask * dropout_mask.float()\n",
    "    def forward(self, x_num, mask, x_seq=None):\n",
    "        B, K, _ = x_num.shape\n",
    "        effective_mask = self.apply_instance_dropout(mask)\n",
    "        num_features = self.num_proj(x_num)\n",
    "        if x_seq is not None:\n",
    "            seq_features = self.encode_sequences(x_seq)\n",
    "            combined = torch.cat([num_features, seq_features], dim=-1)\n",
    "        else:\n",
    "            combined = num_features\n",
    "        h = self.feature_fusion(combined)\n",
    "        src_key_padding_mask = (effective_mask == 0)\n",
    "        h = self.transformer(h, src_key_padding_mask=src_key_padding_mask)\n",
    "        instance_logits = self.instance_classifier(h).squeeze(-1)\n",
    "        instance_logits = instance_logits.masked_fill(effective_mask == 0, float('-inf'))\n",
    "        bag_repr, attention_weights, gates = self.attention_pool(h, effective_mask)\n",
    "        bag_logits = self.classifier(bag_repr).squeeze(-1)\n",
    "        return bag_logits, attention_weights, instance_logits, gates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4632f4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model weights from ../runs/run_20251029_105547/checkpoints/final_model_state_dict.pt\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model and load weights\n",
    "model = TransformerMIL(num_features=len(num_cols))\n",
    "device = torch.device(DEVICE)\n",
    "model = model.to(device)\n",
    "\n",
    "# Try loading different checkpoint formats\n",
    "if MODEL_PATH is not None and Path(MODEL_PATH).exists():\n",
    "    ckpt = torch.load(MODEL_PATH, map_location=device)\n",
    "    # If it's a plain state_dict (mapping of tensors), load directly\n",
    "    if isinstance(ckpt, dict) and any(k.startswith('model') or k.endswith('state_dict') for k in ckpt.keys()):\n",
    "        # support different key names\n",
    "        if 'model_state' in ckpt:\n",
    "            state = ckpt['model_state']\n",
    "        elif 'model_state_dict' in ckpt:\n",
    "            state = ckpt['model_state_dict']\n",
    "        elif 'model' in ckpt and isinstance(ckpt['model'], dict):\n",
    "            state = ckpt['model']\n",
    "        else:\n",
    "            # assume ckpt itself is state_dict-like\n",
    "            state = ckpt\n",
    "    else:\n",
    "        state = ckpt\n",
    "    model.load_state_dict(state)\n",
    "    print(f'Loaded model weights from {MODEL_PATH}')\n",
    "else:\n",
    "    print(f'MODEL_PATH does not exist: {MODEL_PATH}. Please set MODEL_PATH to a valid checkpoint.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d6a072e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded feature scaler from ..\\runs\\run_20251029_105547\\checkpoints\\scaler.joblib\n",
      "Loaded AMP GradScaler from ..\\runs\\run_20251029_105547\\checkpoints\\amp_grad_scaler.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\inbam\\AppData\\Local\\Temp\\ipykernel_14484\\261539347.py:35: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  amp_scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied feature scaler to df_raw\n",
      "Created 121838 bags from 121838 sites\n",
      "Created 121838 bags from 121838 sites\n",
      "Dataset size: 121838 bags, DataLoader batches: 1904\n",
      "Dataset size: 121838 bags, DataLoader batches: 1904\n"
     ]
    }
   ],
   "source": [
    "# Scaler loading (explicit scaler_path and amp_path; minimal/no error-handling)\n",
    "# Define explicit paths (prefer SCALER_PATH if provided, else candidate next to MODEL_PATH)\n",
    "scaler_path = 'scaler.joblib'\n",
    "if SCALER_PATH:\n",
    "    p = Path(SCALER_PATH)\n",
    "    scaler_path = p if p.is_file() else (p / 'scaler.joblib')\n",
    "elif MODEL_PATH:\n",
    "    scaler_path = Path(MODEL_PATH).parent / 'scaler.joblib'\n",
    "\n",
    "amp_path = 'amp_grad_scaler.pt'\n",
    "if SCALER_PATH:\n",
    "    p = Path(SCALER_PATH)\n",
    "    amp_path = (p / 'amp_grad_scaler.pt') if p.is_dir() else (p if p.name == 'amp_grad_scaler.pt' else None)\n",
    "elif MODEL_PATH:\n",
    "    amp_path = Path(MODEL_PATH).parent / 'amp_grad_scaler.pt'\n",
    "\n",
    "# Load feature scaler if scaler_path exists\n",
    "feature_scaler = None\n",
    "saved_num_cols = None\n",
    "if scaler_path is not None and Path(scaler_path).exists():\n",
    "    payload = joblib.load(scaler_path)\n",
    "    if isinstance(payload, dict) and 'scaler' in payload:\n",
    "        feature_scaler = payload['scaler']\n",
    "        saved_num_cols = payload.get('num_cols', None)\n",
    "    else:\n",
    "        feature_scaler = payload\n",
    "    print(f'Loaded feature scaler from {scaler_path}')\n",
    "else:\n",
    "    print('No scaler_path found; feature_scaler remains None')\n",
    "\n",
    "# Load AMP GradScaler directly if amp_path exists (minimal loading)\n",
    "amp_scaler = None\n",
    "if amp_path is not None and Path(amp_path).exists():\n",
    "    amp_state = torch.load(amp_path, map_location='cpu')\n",
    "    amp_scaler = GradScaler()\n",
    "    amp_scaler.load_state_dict(amp_state)\n",
    "    print(f'Loaded AMP GradScaler from {amp_path}')\n",
    "else:\n",
    "    print('No amp_path found; amp_scaler remains None')\n",
    "\n",
    "# Verify column consistency when possible\n",
    "if feature_scaler is not None and saved_num_cols is not None:\n",
    "    if list(saved_num_cols) != list(num_cols):\n",
    "        print('WARNING: numeric column list in saved scaler differs from current num_cols.')\n",
    "        print(f'Saved: {saved_num_cols}')\n",
    "        print(f'Current: {num_cols}')\n",
    "    else:\n",
    "        print('Saved scaler column order matches current num_cols')\n",
    "\n",
    "# Apply scaling if we have a feature scaler\n",
    "if feature_scaler is not None:\n",
    "    df_raw[num_cols] = feature_scaler.transform(df_raw[num_cols])\n",
    "    print('Applied feature scaler to df_raw')\n",
    "\n",
    "# Rebuild bags and dataset now that df_raw is scaled\n",
    "bags = create_bags_unlabeled(df_raw, site_key, num_cols, seq_col, min_reads=1, max_reads=BAG_SIZE)\n",
    "dataset = RNA_MIL_Dataset_Unlabeled(bags, bag_size=BAG_SIZE, pad_idx=PAD_IDX)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "print(f'Dataset size: {len(dataset)} bags, DataLoader batches: {len(dataloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07a7cba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_PATH -> ../runs/run_20251029_105547/checkpoints/final_model_state_dict.pt\n",
      "Checkpoint type: <class 'collections.OrderedDict'>\n",
      "Top-level keys: ['seq_encoder.emb.weight', 'seq_encoder.convs.0.weight', 'seq_encoder.convs.0.bias', 'seq_encoder.convs.1.weight', 'seq_encoder.convs.1.bias', 'seq_encoder.convs.2.weight', 'seq_encoder.convs.2.bias', 'seq_encoder.convs.3.weight', 'seq_encoder.convs.3.bias', 'seq_encoder.attentions.0.weight', 'seq_encoder.attentions.0.bias', 'seq_encoder.attentions.1.weight', 'seq_encoder.attentions.1.bias', 'seq_encoder.attentions.2.weight', 'seq_encoder.attentions.2.bias', 'seq_encoder.attentions.3.weight', 'seq_encoder.attentions.3.bias', 'seq_encoder.proj.weight', 'seq_encoder.proj.bias', 'seq_encoder.norm.weight', 'seq_encoder.norm.bias', 'num_proj.0.weight', 'num_proj.0.bias', 'num_proj.1.weight', 'num_proj.1.bias', 'feature_fusion.0.weight', 'feature_fusion.0.bias', 'feature_fusion.1.weight', 'feature_fusion.1.bias', 'feature_fusion.4.weight', 'feature_fusion.4.bias', 'feature_fusion.5.weight', 'feature_fusion.5.bias', 'transformer.layers.0.self_attn.in_proj_weight', 'transformer.layers.0.self_attn.in_proj_bias', 'transformer.layers.0.self_attn.out_proj.weight', 'transformer.layers.0.self_attn.out_proj.bias', 'transformer.layers.0.linear1.weight', 'transformer.layers.0.linear1.bias', 'transformer.layers.0.linear2.weight', 'transformer.layers.0.linear2.bias', 'transformer.layers.0.norm1.weight', 'transformer.layers.0.norm1.bias', 'transformer.layers.0.norm2.weight', 'transformer.layers.0.norm2.bias', 'transformer.layers.1.self_attn.in_proj_weight', 'transformer.layers.1.self_attn.in_proj_bias', 'transformer.layers.1.self_attn.out_proj.weight', 'transformer.layers.1.self_attn.out_proj.bias', 'transformer.layers.1.linear1.weight', 'transformer.layers.1.linear1.bias', 'transformer.layers.1.linear2.weight', 'transformer.layers.1.linear2.bias', 'transformer.layers.1.norm1.weight', 'transformer.layers.1.norm1.bias', 'transformer.layers.1.norm2.weight', 'transformer.layers.1.norm2.bias', 'transformer.layers.2.self_attn.in_proj_weight', 'transformer.layers.2.self_attn.in_proj_bias', 'transformer.layers.2.self_attn.out_proj.weight', 'transformer.layers.2.self_attn.out_proj.bias', 'transformer.layers.2.linear1.weight', 'transformer.layers.2.linear1.bias', 'transformer.layers.2.linear2.weight', 'transformer.layers.2.linear2.bias', 'transformer.layers.2.norm1.weight', 'transformer.layers.2.norm1.bias', 'transformer.layers.2.norm2.weight', 'transformer.layers.2.norm2.bias', 'transformer.layers.3.self_attn.in_proj_weight', 'transformer.layers.3.self_attn.in_proj_bias', 'transformer.layers.3.self_attn.out_proj.weight', 'transformer.layers.3.self_attn.out_proj.bias', 'transformer.layers.3.linear1.weight', 'transformer.layers.3.linear1.bias', 'transformer.layers.3.linear2.weight', 'transformer.layers.3.linear2.bias', 'transformer.layers.3.norm1.weight', 'transformer.layers.3.norm1.bias', 'transformer.layers.3.norm2.weight', 'transformer.layers.3.norm2.bias', 'attention_pool.attention_heads.0.0.weight', 'attention_pool.attention_heads.0.0.bias', 'attention_pool.attention_heads.0.3.weight', 'attention_pool.attention_heads.0.3.bias', 'attention_pool.attention_heads.1.0.weight', 'attention_pool.attention_heads.1.0.bias', 'attention_pool.attention_heads.1.3.weight', 'attention_pool.attention_heads.1.3.bias', 'attention_pool.attention_heads.2.0.weight', 'attention_pool.attention_heads.2.0.bias', 'attention_pool.attention_heads.2.3.weight', 'attention_pool.attention_heads.2.3.bias', 'attention_pool.attention_heads.3.0.weight', 'attention_pool.attention_heads.3.0.bias', 'attention_pool.attention_heads.3.3.weight', 'attention_pool.attention_heads.3.3.bias', 'attention_pool.gate.0.weight', 'attention_pool.gate.0.bias', 'attention_pool.gate.3.weight', 'attention_pool.gate.3.bias', 'attention_pool.fusion.0.weight', 'attention_pool.fusion.0.bias', 'attention_pool.fusion.1.weight', 'attention_pool.fusion.1.bias', 'classifier.0.weight', 'classifier.0.bias', 'classifier.1.weight', 'classifier.1.bias', 'classifier.4.weight', 'classifier.4.bias', 'classifier.5.weight', 'classifier.5.bias', 'classifier.8.weight', 'classifier.8.bias', 'instance_classifier.0.weight', 'instance_classifier.0.bias', 'instance_classifier.1.weight', 'instance_classifier.1.bias', 'instance_classifier.4.weight', 'instance_classifier.4.bias', 'instance_classifier.7.weight', 'instance_classifier.7.bias']\n",
      "Found state dict with 123 keys; sample keys:\n",
      "['seq_encoder.emb.weight',\n",
      " 'seq_encoder.convs.0.weight',\n",
      " 'seq_encoder.convs.0.bias',\n",
      " 'seq_encoder.convs.1.weight',\n",
      " 'seq_encoder.convs.1.bias',\n",
      " 'seq_encoder.convs.2.weight',\n",
      " 'seq_encoder.convs.2.bias',\n",
      " 'seq_encoder.convs.3.weight',\n",
      " 'seq_encoder.convs.3.bias',\n",
      " 'seq_encoder.attentions.0.weight',\n",
      " 'seq_encoder.attentions.0.bias',\n",
      " 'seq_encoder.attentions.1.weight',\n",
      " 'seq_encoder.attentions.1.bias',\n",
      " 'seq_encoder.attentions.2.weight',\n",
      " 'seq_encoder.attentions.2.bias',\n",
      " 'seq_encoder.attentions.3.weight',\n",
      " 'seq_encoder.attentions.3.bias',\n",
      " 'seq_encoder.proj.weight',\n",
      " 'seq_encoder.proj.bias',\n",
      " 'seq_encoder.norm.weight']\n",
      "Current model expects 123 keys; sample:\n",
      "['seq_encoder.emb.weight',\n",
      " 'seq_encoder.convs.0.weight',\n",
      " 'seq_encoder.convs.0.bias',\n",
      " 'seq_encoder.convs.1.weight',\n",
      " 'seq_encoder.convs.1.bias',\n",
      " 'seq_encoder.convs.2.weight',\n",
      " 'seq_encoder.convs.2.bias',\n",
      " 'seq_encoder.convs.3.weight',\n",
      " 'seq_encoder.convs.3.bias',\n",
      " 'seq_encoder.attentions.0.weight',\n",
      " 'seq_encoder.attentions.0.bias',\n",
      " 'seq_encoder.attentions.1.weight',\n",
      " 'seq_encoder.attentions.1.bias',\n",
      " 'seq_encoder.attentions.2.weight',\n",
      " 'seq_encoder.attentions.2.bias',\n",
      " 'seq_encoder.attentions.3.weight',\n",
      " 'seq_encoder.attentions.3.bias',\n",
      " 'seq_encoder.proj.weight',\n",
      " 'seq_encoder.proj.bias',\n",
      " 'seq_encoder.norm.weight']\n",
      "load_state_dict(strict=False) result:\n",
      "  missing_keys (keys required by model but absent in state): 0\n",
      "  unexpected_keys (keys present in state but not used by model): 0\n",
      "Current model total params: 1,528,179\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic 1 — checkpoint & model state mapping\n",
    "import torch, pprint\n",
    "from pathlib import Path\n",
    "\n",
    "print('MODEL_PATH ->', MODEL_PATH)\n",
    "if MODEL_PATH is None or not Path(MODEL_PATH).exists():\n",
    "    print('MODEL_PATH is missing or does not exist. Aborting checkpoint diagnostic.')\n",
    "else:\n",
    "    ckpt = torch.load(MODEL_PATH, map_location='cpu')\n",
    "    print('Checkpoint type:', type(ckpt))\n",
    "    if isinstance(ckpt, dict):\n",
    "        print('Top-level keys:', list(ckpt.keys()))\n",
    "    # locate candidate state dict\n",
    "    def find_state_dict(obj):\n",
    "        if isinstance(obj, dict) and obj and all(isinstance(v, torch.Tensor) for v in list(obj.values())[:5]):\n",
    "            return obj\n",
    "        for k in ['model_state_dict','model_state','state_dict','model']:\n",
    "            if isinstance(obj, dict) and k in obj and isinstance(obj[k], dict):\n",
    "                return obj[k]\n",
    "        return None\n",
    "    state = find_state_dict(ckpt) or (ckpt if isinstance(ckpt, dict) and any(isinstance(v, torch.Tensor) for v in ckpt.values()) else None)\n",
    "    if state is None:\n",
    "        print('Could not find a state-dict-like object in the checkpoint.')\n",
    "    else:\n",
    "        state_keys = list(state.keys())\n",
    "        print(f'Found state dict with {len(state_keys)} keys; sample keys:')\n",
    "        pprint.pprint(state_keys[:20])\n",
    "        # instantiate a fresh model with current num_cols\n",
    "        model_tmp = TransformerMIL(num_features=len(num_cols))\n",
    "        model_keys = list(model_tmp.state_dict().keys())\n",
    "        print(f'Current model expects {len(model_keys)} keys; sample:')\n",
    "        pprint.pprint(model_keys[:20])\n",
    "        # check missing/unexpected when loading with strict=False\n",
    "        load_res = model_tmp.load_state_dict(state, strict=False)\n",
    "        print('load_state_dict(strict=False) result:')\n",
    "        print('  missing_keys (keys required by model but absent in state):', len(load_res.missing_keys))\n",
    "        if load_res.missing_keys:\n",
    "            print('    sample missing:', load_res.missing_keys[:10])\n",
    "        print('  unexpected_keys (keys present in state but not used by model):', len(load_res.unexpected_keys))\n",
    "        if load_res.unexpected_keys:\n",
    "            print('    sample unexpected:', load_res.unexpected_keys[:10])\n",
    "        model_param_count = sum(p.numel() for p in model_tmp.parameters())\n",
    "        print(f'Current model total params: {model_param_count:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b687810a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved scaler_path -> ..\\runs\\run_20251029_105547\\checkpoints\\scaler.joblib\n",
      "Loaded scaler payload type: <class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "saved_num_cols -> None\n",
      "current num_cols -> ['dwell_-1', 'std_-1', 'mean_-1', 'dwell_0', 'std_0', 'mean_0', 'dwell_+1', 'std_+1', 'mean_+1', 'mean_0_minus_mean_-1', 'mean_0_minus_mean_+1', 'dwell_0_minus_dwell_-1', 'dwell_0_minus_dwell_+1', 'std_0_minus_avg_neighbor_std']\n",
      "scaler mean_ (first 10): [8.11200000e-03 4.34151800e+00 1.10902820e+02 8.14000000e-03\n",
      " 5.16849800e+00 1.11011468e+02 7.07700000e-03 2.97629800e+00\n",
      " 8.62754340e+01 1.08648000e-01]\n",
      "scaler scale_ (first 10): [5.4180000e-03 2.5795620e+00 1.1918103e+01 5.3000000e-03 3.0072430e+00\n",
      " 1.3004381e+01 4.3860000e-03 1.6960540e+00 5.5726260e+00 1.5378791e+01]\n",
      "Sampling raw data stats (first batch of reads)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading raw data: 100%|██████████| 121838/121838 [00:48<00:00, 2497.72it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 11027106 reads from 121838 sites\n",
      "Raw feature describe:\n",
      "Raw feature describe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dwell_-1</th>\n",
       "      <th>std_-1</th>\n",
       "      <th>mean_-1</th>\n",
       "      <th>dwell_0</th>\n",
       "      <th>std_0</th>\n",
       "      <th>mean_0</th>\n",
       "      <th>dwell_+1</th>\n",
       "      <th>std_+1</th>\n",
       "      <th>mean_+1</th>\n",
       "      <th>mean_0_minus_mean_-1</th>\n",
       "      <th>mean_0_minus_mean_+1</th>\n",
       "      <th>dwell_0_minus_dwell_-1</th>\n",
       "      <th>dwell_0_minus_dwell_+1</th>\n",
       "      <th>std_0_minus_avg_neighbor_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.102711e+07</td>\n",
       "      <td>1.102711e+07</td>\n",
       "      <td>1.102711e+07</td>\n",
       "      <td>1.102711e+07</td>\n",
       "      <td>1.102711e+07</td>\n",
       "      <td>1.102711e+07</td>\n",
       "      <td>1.102711e+07</td>\n",
       "      <td>1.102711e+07</td>\n",
       "      <td>1.102711e+07</td>\n",
       "      <td>1.102711e+07</td>\n",
       "      <td>1.102711e+07</td>\n",
       "      <td>1.102711e+07</td>\n",
       "      <td>1.102711e+07</td>\n",
       "      <td>1.102711e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.106457e-03</td>\n",
       "      <td>4.347531e+00</td>\n",
       "      <td>1.109025e+02</td>\n",
       "      <td>8.149364e-03</td>\n",
       "      <td>5.182957e+00</td>\n",
       "      <td>1.110816e+02</td>\n",
       "      <td>7.077341e-03</td>\n",
       "      <td>2.981141e+00</td>\n",
       "      <td>8.625382e+01</td>\n",
       "      <td>1.791089e-01</td>\n",
       "      <td>2.482776e+01</td>\n",
       "      <td>4.290677e-05</td>\n",
       "      <td>1.072024e-03</td>\n",
       "      <td>1.518621e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.411981e-03</td>\n",
       "      <td>2.577925e+00</td>\n",
       "      <td>1.192639e+01</td>\n",
       "      <td>5.301427e-03</td>\n",
       "      <td>3.008630e+00</td>\n",
       "      <td>1.302800e+01</td>\n",
       "      <td>4.385762e-03</td>\n",
       "      <td>1.699636e+00</td>\n",
       "      <td>5.556484e+00</td>\n",
       "      <td>1.541130e+01</td>\n",
       "      <td>1.537541e+01</td>\n",
       "      <td>7.571703e-03</td>\n",
       "      <td>6.759301e-03</td>\n",
       "      <td>3.202656e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.660000e-03</td>\n",
       "      <td>9.400000e-02</td>\n",
       "      <td>7.320000e+01</td>\n",
       "      <td>1.660000e-03</td>\n",
       "      <td>4.400000e-02</td>\n",
       "      <td>7.540000e+01</td>\n",
       "      <td>1.660000e-03</td>\n",
       "      <td>1.360000e-01</td>\n",
       "      <td>6.100000e+01</td>\n",
       "      <td>-6.710000e+01</td>\n",
       "      <td>-4.470000e+01</td>\n",
       "      <td>-1.152800e-01</td>\n",
       "      <td>-9.736000e-02</td>\n",
       "      <td>-9.719000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.320000e-03</td>\n",
       "      <td>2.500000e+00</td>\n",
       "      <td>1.040000e+02</td>\n",
       "      <td>4.490000e-03</td>\n",
       "      <td>2.930000e+00</td>\n",
       "      <td>9.870000e+01</td>\n",
       "      <td>4.090000e-03</td>\n",
       "      <td>1.930000e+00</td>\n",
       "      <td>8.200000e+01</td>\n",
       "      <td>-7.000000e+00</td>\n",
       "      <td>9.800000e+00</td>\n",
       "      <td>-3.760000e-03</td>\n",
       "      <td>-2.430000e-03</td>\n",
       "      <td>-4.600000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.640000e-03</td>\n",
       "      <td>3.550000e+00</td>\n",
       "      <td>1.110000e+02</td>\n",
       "      <td>6.690000e-03</td>\n",
       "      <td>4.230000e+00</td>\n",
       "      <td>1.120000e+02</td>\n",
       "      <td>5.980000e-03</td>\n",
       "      <td>2.510000e+00</td>\n",
       "      <td>8.640000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.770000e+01</td>\n",
       "      <td>6.000000e-05</td>\n",
       "      <td>6.700000e-04</td>\n",
       "      <td>9.450000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.020000e-02</td>\n",
       "      <td>5.570000e+00</td>\n",
       "      <td>1.200000e+02</td>\n",
       "      <td>1.030000e-02</td>\n",
       "      <td>6.890000e+00</td>\n",
       "      <td>1.230000e+02</td>\n",
       "      <td>8.630000e-03</td>\n",
       "      <td>3.470000e+00</td>\n",
       "      <td>9.040000e+01</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>3.890000e+01</td>\n",
       "      <td>3.940000e-03</td>\n",
       "      <td>4.310000e-03</td>\n",
       "      <td>3.135000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.200000e-01</td>\n",
       "      <td>2.060000e+02</td>\n",
       "      <td>1.530000e+02</td>\n",
       "      <td>1.380000e-01</td>\n",
       "      <td>2.060000e+02</td>\n",
       "      <td>1.560000e+02</td>\n",
       "      <td>1.030000e-01</td>\n",
       "      <td>1.840000e+02</td>\n",
       "      <td>1.430000e+02</td>\n",
       "      <td>5.570000e+01</td>\n",
       "      <td>7.660000e+01</td>\n",
       "      <td>1.346800e-01</td>\n",
       "      <td>1.297000e-01</td>\n",
       "      <td>2.006400e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dwell_-1        std_-1       mean_-1       dwell_0         std_0  \\\n",
       "count  1.102711e+07  1.102711e+07  1.102711e+07  1.102711e+07  1.102711e+07   \n",
       "mean   8.106457e-03  4.347531e+00  1.109025e+02  8.149364e-03  5.182957e+00   \n",
       "std    5.411981e-03  2.577925e+00  1.192639e+01  5.301427e-03  3.008630e+00   \n",
       "min    1.660000e-03  9.400000e-02  7.320000e+01  1.660000e-03  4.400000e-02   \n",
       "25%    4.320000e-03  2.500000e+00  1.040000e+02  4.490000e-03  2.930000e+00   \n",
       "50%    6.640000e-03  3.550000e+00  1.110000e+02  6.690000e-03  4.230000e+00   \n",
       "75%    1.020000e-02  5.570000e+00  1.200000e+02  1.030000e-02  6.890000e+00   \n",
       "max    1.200000e-01  2.060000e+02  1.530000e+02  1.380000e-01  2.060000e+02   \n",
       "\n",
       "             mean_0      dwell_+1        std_+1       mean_+1  \\\n",
       "count  1.102711e+07  1.102711e+07  1.102711e+07  1.102711e+07   \n",
       "mean   1.110816e+02  7.077341e-03  2.981141e+00  8.625382e+01   \n",
       "std    1.302800e+01  4.385762e-03  1.699636e+00  5.556484e+00   \n",
       "min    7.540000e+01  1.660000e-03  1.360000e-01  6.100000e+01   \n",
       "25%    9.870000e+01  4.090000e-03  1.930000e+00  8.200000e+01   \n",
       "50%    1.120000e+02  5.980000e-03  2.510000e+00  8.640000e+01   \n",
       "75%    1.230000e+02  8.630000e-03  3.470000e+00  9.040000e+01   \n",
       "max    1.560000e+02  1.030000e-01  1.840000e+02  1.430000e+02   \n",
       "\n",
       "       mean_0_minus_mean_-1  mean_0_minus_mean_+1  dwell_0_minus_dwell_-1  \\\n",
       "count          1.102711e+07          1.102711e+07            1.102711e+07   \n",
       "mean           1.791089e-01          2.482776e+01            4.290677e-05   \n",
       "std            1.541130e+01          1.537541e+01            7.571703e-03   \n",
       "min           -6.710000e+01         -4.470000e+01           -1.152800e-01   \n",
       "25%           -7.000000e+00          9.800000e+00           -3.760000e-03   \n",
       "50%            2.000000e+00          2.770000e+01            6.000000e-05   \n",
       "75%            1.000000e+01          3.890000e+01            3.940000e-03   \n",
       "max            5.570000e+01          7.660000e+01            1.346800e-01   \n",
       "\n",
       "       dwell_0_minus_dwell_+1  std_0_minus_avg_neighbor_std  \n",
       "count            1.102711e+07                  1.102711e+07  \n",
       "mean             1.072024e-03                  1.518621e+00  \n",
       "std              6.759301e-03                  3.202656e+00  \n",
       "min             -9.736000e-02                 -9.719000e+01  \n",
       "25%             -2.430000e-03                 -4.600000e-01  \n",
       "50%              6.700000e-04                  9.450000e-01  \n",
       "75%              4.310000e-03                  3.135000e+00  \n",
       "max              1.297000e-01                  2.006400e+02  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed feature describe (first 10 cols):\n",
      "                           count      mean       std       min       25%  \\\n",
      "dwell_-1              11027106.0 -0.001053  0.998892 -1.190879 -0.699922   \n",
      "std_-1                11027106.0  0.002331  0.999365 -1.646604 -0.713888   \n",
      "mean_-1               11027106.0 -0.000029  1.000695 -3.163492 -0.579188   \n",
      "dwell_0               11027106.0  0.001728  1.000354 -1.222784 -0.688776   \n",
      "std_0                 11027106.0  0.004808  1.000461 -1.704052 -0.744369   \n",
      "mean_0                11027106.0  0.005391  1.001816 -2.738421 -0.946717   \n",
      "dwell_+1              11027106.0  0.000146  0.999885 -1.234922 -0.680920   \n",
      "std_+1                11027106.0  0.002855  1.002112 -1.674651 -0.616902   \n",
      "mean_+1               11027106.0 -0.003879  0.997103 -4.535641 -0.767221   \n",
      "mean_0_minus_mean_-1  11027106.0  0.004582  1.002114 -4.370217 -0.462237   \n",
      "\n",
      "                           50%       75%         max  \n",
      "dwell_-1             -0.271718  0.385353   20.651192  \n",
      "std_-1               -0.306842  0.476237   78.175465  \n",
      "mean_-1               0.008154  0.763308    3.532205  \n",
      "dwell_0              -0.273647  0.407543   24.503925  \n",
      "std_0                -0.312079  0.572452   66.782603  \n",
      "mean_0                0.076015  0.921884    3.459490  \n",
      "dwell_+1             -0.250030  0.354128   21.869009  \n",
      "std_+1               -0.274931  0.291088  106.732295  \n",
      "mean_+1               0.022353  0.740148   10.179144  \n",
      "mean_0_minus_mean_-1  0.122984  0.643181    3.614806  \n",
      "Any NaNs after transform? -> False\n",
      "                           count      mean       std       min       25%  \\\n",
      "dwell_-1              11027106.0 -0.001053  0.998892 -1.190879 -0.699922   \n",
      "std_-1                11027106.0  0.002331  0.999365 -1.646604 -0.713888   \n",
      "mean_-1               11027106.0 -0.000029  1.000695 -3.163492 -0.579188   \n",
      "dwell_0               11027106.0  0.001728  1.000354 -1.222784 -0.688776   \n",
      "std_0                 11027106.0  0.004808  1.000461 -1.704052 -0.744369   \n",
      "mean_0                11027106.0  0.005391  1.001816 -2.738421 -0.946717   \n",
      "dwell_+1              11027106.0  0.000146  0.999885 -1.234922 -0.680920   \n",
      "std_+1                11027106.0  0.002855  1.002112 -1.674651 -0.616902   \n",
      "mean_+1               11027106.0 -0.003879  0.997103 -4.535641 -0.767221   \n",
      "mean_0_minus_mean_-1  11027106.0  0.004582  1.002114 -4.370217 -0.462237   \n",
      "\n",
      "                           50%       75%         max  \n",
      "dwell_-1             -0.271718  0.385353   20.651192  \n",
      "std_-1               -0.306842  0.476237   78.175465  \n",
      "mean_-1               0.008154  0.763308    3.532205  \n",
      "dwell_0              -0.273647  0.407543   24.503925  \n",
      "std_0                -0.312079  0.572452   66.782603  \n",
      "mean_0                0.076015  0.921884    3.459490  \n",
      "dwell_+1             -0.250030  0.354128   21.869009  \n",
      "std_+1               -0.274931  0.291088  106.732295  \n",
      "mean_+1               0.022353  0.740148   10.179144  \n",
      "mean_0_minus_mean_-1  0.122984  0.643181    3.614806  \n",
      "Any NaNs after transform? -> False\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic 2 — scaler and feature statistics\n",
    "import joblib, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Resolve scaler path same logic as notebook\n",
    "scaler_path = Path('scaler.joblib')\n",
    "if SCALER_PATH:\n",
    "    p = Path(SCALER_PATH)\n",
    "    scaler_path = p if p.is_file() else (p / 'scaler.joblib')\n",
    "elif MODEL_PATH:\n",
    "    scaler_path = Path(MODEL_PATH).parent / 'scaler.joblib'\n",
    "\n",
    "print('Resolved scaler_path ->', scaler_path)\n",
    "if not scaler_path.exists():\n",
    "    raise FileNotFoundError(f'Scaler file not found at path: {scaler_path}.')\n",
    "payload = joblib.load(scaler_path)\n",
    "print('Loaded scaler payload type:', type(payload))\n",
    "if isinstance(payload, dict):\n",
    "    print('Payload keys:', list(payload.keys()))\n",
    "    feature_scaler = payload.get('scaler', payload)\n",
    "    saved_cols = payload.get('num_cols', None)\n",
    "else:\n",
    "    feature_scaler = payload\n",
    "    saved_cols = None\n",
    "print('saved_num_cols ->', saved_cols)\n",
    "print('current num_cols ->', num_cols)\n",
    "if hasattr(feature_scaler, 'mean_'):\n",
    "    print('scaler mean_ (first 10):', np.round(feature_scaler.mean_[:10], 6))\n",
    "if hasattr(feature_scaler, 'scale_'):\n",
    "    print('scaler scale_ (first 10):', np.round(feature_scaler.scale_[:10], 6))\n",
    "print('Sampling raw data stats (first batch of reads)')\n",
    "df_sample = load_unlabeled_data(DATA_FILE)\n",
    "if len(df_sample) == 0:\n",
    "    raise RuntimeError('No reads found in DATA_FILE')\n",
    "import pandas as pd\n",
    "print('Raw feature describe:')\n",
    "display(df_sample[num_cols].describe())\n",
    "transformed = feature_scaler.transform(df_sample[num_cols]) if feature_scaler is not None else None\n",
    "if transformed is not None:\n",
    "    print('Transformed feature describe (first 10 cols):')\n",
    "    print(pd.DataFrame(transformed, columns=num_cols).describe().transpose().head(10))\n",
    "    print('Any NaNs after transform? ->', np.isnan(transformed).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a09acd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking a single batch from dataloader (no shuffling)\n",
      "logits -> mean: -1.327085, std: 1.707713, min: -3.522403, max: 3.649587\n",
      "probs -> mean: 0.273978, std: 0.274931, min: 0.028681, max: 0.974657\n",
      "Sample logits (first 10): [-3.363253   -1.7439674  -3.4965966   0.368535   -2.7977657  -0.25326368\n",
      " -2.7917993  -2.1160352   1.2464864  -1.9528238 ]\n",
      "Sample probs (first 10): [0.03346385 0.1488097  0.02940922 0.5911049  0.05744503 0.4370204\n",
      " 0.05776894 0.10754802 0.776691   0.12424579]\n",
      "idx=0 meta={'transcript_id': 'ENST00000000233', 'transcript_position': 244, 'n_reads': 40} prob=0.033464 logits=-3.363253\n",
      "idx=1 meta={'transcript_id': 'ENST00000000233', 'transcript_position': 261, 'n_reads': 40} prob=0.148810 logits=-1.743967\n",
      "idx=2 meta={'transcript_id': 'ENST00000000233', 'transcript_position': 316, 'n_reads': 40} prob=0.029409 logits=-3.496597\n",
      "idx=3 meta={'transcript_id': 'ENST00000000233', 'transcript_position': 332, 'n_reads': 40} prob=0.591105 logits=0.368535\n",
      "idx=4 meta={'transcript_id': 'ENST00000000233', 'transcript_position': 368, 'n_reads': 40} prob=0.057445 logits=-2.797766\n",
      "idx=5 meta={'transcript_id': 'ENST00000000233', 'transcript_position': 404, 'n_reads': 40} prob=0.437020 logits=-0.253264\n",
      "idx=6 meta={'transcript_id': 'ENST00000000233', 'transcript_position': 431, 'n_reads': 40} prob=0.057769 logits=-2.791799\n",
      "idx=7 meta={'transcript_id': 'ENST00000000233', 'transcript_position': 440, 'n_reads': 40} prob=0.107548 logits=-2.116035\n",
      "idx=8 meta={'transcript_id': 'ENST00000000233', 'transcript_position': 471, 'n_reads': 40} prob=0.776691 logits=1.246486\n",
      "idx=9 meta={'transcript_id': 'ENST00000000233', 'transcript_position': 539, 'n_reads': 40} prob=0.124246 logits=-1.952824\n",
      "Model parameter means (sample 10): [np.float32(0.088531494), np.float32(-0.014853934), np.float32(-0.04645916), np.float32(0.0017311582), np.float32(0.011085026), np.float32(-0.0037776043), np.float32(0.00051043415), np.float32(-0.0013070598), np.float32(-0.019572794), np.float32(-0.0040665474)]\n",
      "logits -> mean: -1.327085, std: 1.707713, min: -3.522403, max: 3.649587\n",
      "probs -> mean: 0.273978, std: 0.274931, min: 0.028681, max: 0.974657\n",
      "Sample logits (first 10): [-3.363253   -1.7439674  -3.4965966   0.368535   -2.7977657  -0.25326368\n",
      " -2.7917993  -2.1160352   1.2464864  -1.9528238 ]\n",
      "Sample probs (first 10): [0.03346385 0.1488097  0.02940922 0.5911049  0.05744503 0.4370204\n",
      " 0.05776894 0.10754802 0.776691   0.12424579]\n",
      "idx=0 meta={'transcript_id': 'ENST00000000233', 'transcript_position': 244, 'n_reads': 40} prob=0.033464 logits=-3.363253\n",
      "idx=1 meta={'transcript_id': 'ENST00000000233', 'transcript_position': 261, 'n_reads': 40} prob=0.148810 logits=-1.743967\n",
      "idx=2 meta={'transcript_id': 'ENST00000000233', 'transcript_position': 316, 'n_reads': 40} prob=0.029409 logits=-3.496597\n",
      "idx=3 meta={'transcript_id': 'ENST00000000233', 'transcript_position': 332, 'n_reads': 40} prob=0.591105 logits=0.368535\n",
      "idx=4 meta={'transcript_id': 'ENST00000000233', 'transcript_position': 368, 'n_reads': 40} prob=0.057445 logits=-2.797766\n",
      "idx=5 meta={'transcript_id': 'ENST00000000233', 'transcript_position': 404, 'n_reads': 40} prob=0.437020 logits=-0.253264\n",
      "idx=6 meta={'transcript_id': 'ENST00000000233', 'transcript_position': 431, 'n_reads': 40} prob=0.057769 logits=-2.791799\n",
      "idx=7 meta={'transcript_id': 'ENST00000000233', 'transcript_position': 440, 'n_reads': 40} prob=0.107548 logits=-2.116035\n",
      "idx=8 meta={'transcript_id': 'ENST00000000233', 'transcript_position': 471, 'n_reads': 40} prob=0.776691 logits=1.246486\n",
      "idx=9 meta={'transcript_id': 'ENST00000000233', 'transcript_position': 539, 'n_reads': 40} prob=0.124246 logits=-1.952824\n",
      "Model parameter means (sample 10): [np.float32(0.088531494), np.float32(-0.014853934), np.float32(-0.04645916), np.float32(0.0017311582), np.float32(0.011085026), np.float32(-0.0037776043), np.float32(0.00051043415), np.float32(-0.0013070598), np.float32(-0.019572794), np.float32(-0.0040665474)]\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic 3 — small forward pass and logits/probability stats\n",
    "import torch\n",
    "model.eval()\n",
    "print('Taking a single batch from dataloader (no shuffling)')\n",
    "batch = next(iter(dataloader))\n",
    "x_num, x_seq, mask = batch\n",
    "x_num = x_num.to(device)\n",
    "x_seq = x_seq.to(device)\n",
    "mask  = mask.to(device)\n",
    "with torch.no_grad():\n",
    "    bag_logits, attn, inst_logits, gates = model(x_num=x_num, x_seq=x_seq, mask=mask)\n",
    "logits = bag_logits.cpu().numpy()\n",
    "probs = torch.sigmoid(torch.tensor(logits)).numpy()\n",
    "import numpy as _np\n",
    "print('logits -> mean: {:.6f}, std: {:.6f}, min: {:.6f}, max: {:.6f}'.format(_np.mean(logits), _np.std(logits), _np.min(logits), _np.max(logits)))\n",
    "print('probs -> mean: {:.6f}, std: {:.6f}, min: {:.6f}, max: {:.6f}'.format(_np.mean(probs), _np.std(probs), _np.min(probs), _np.max(probs)))\n",
    "print('Sample logits (first 10):', logits[:10])\n",
    "print('Sample probs (first 10):', probs[:10])\n",
    "for i in range(min(10, len(probs))):\n",
    "    meta = dataset.get_metadata(i)\n",
    "    print(f'idx={i} meta={meta} prob={float(probs[i]):.6f} logits={float(logits[i]):.6f}')\n",
    "if _np.allclose(logits, logits[0], atol=1e-6):\n",
    "    print('All logits nearly identical — possible causes: constant inputs, collapsed model, or scale mismatch.')\n",
    "param_means = [p.detach().cpu().numpy().mean() for p in model.parameters() if p.numel() > 0]\n",
    "print('Model parameter means (sample 10):', param_means[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a009bed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference: 100%|██████████| 1904/1904 [00:28<00:00, 67.74it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to ..\\predictions\\dataset0_predictions_transformers.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>transcript_position</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>0.033464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>261</td>\n",
       "      <td>0.148810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>316</td>\n",
       "      <td>0.029409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>332</td>\n",
       "      <td>0.591105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>368</td>\n",
       "      <td>0.057445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     transcript_id  transcript_position     score\n",
       "0  ENST00000000233                  244  0.033464\n",
       "1  ENST00000000233                  261  0.148810\n",
       "2  ENST00000000233                  316  0.029409\n",
       "3  ENST00000000233                  332  0.591105\n",
       "4  ENST00000000233                  368  0.057445"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run inference and save per-site probabilities\n",
    "model.eval()\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(tqdm(dataloader, desc='Running inference')):\n",
    "        x_num, x_seq, mask = batch\n",
    "        x_num = x_num.to(device)\n",
    "        x_seq = x_seq.to(device)\n",
    "        mask  = mask.to(device)\n",
    "        bag_logits, attn, inst_logits, gates = model(x_num=x_num, x_seq=x_seq, mask=mask)\n",
    "        probs = torch.sigmoid(bag_logits).cpu().numpy()\n",
    "        batch_start = batch_idx * BATCH_SIZE\n",
    "        for i in range(len(probs)):\n",
    "            meta = dataset.get_metadata(batch_start + i)\n",
    "            results.append({\n",
    "                'transcript_id': meta['transcript_id'],\n",
    "                'transcript_position': meta['transcript_position'],\n",
    "                'score': float(probs[i])\n",
    "            })\n",
    "\n",
    "# Build DataFrame and save\n",
    "pred_df = pd.DataFrame(results)\n",
    "out_path = Path(OUTPUT_CSV)\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "pred_df.to_csv(out_path, index=False)\n",
    "print(f'Saved predictions to {out_path}')\n",
    "pred_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
